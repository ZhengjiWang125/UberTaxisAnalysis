{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import logging\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import Column, Integer, String\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this part will download all the files in the local repo, but it will take a long time. \n",
    "Depending on the machine it runs on, it might throw error due to large size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Weather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All weather csv are cleaned and seperated into hours part and days part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the clean version of weather csv and seprated into two parts\n",
    "def create_weather_csv(filename):\n",
    "    # make sure the output title is consistent \n",
    "    title1 = \"\"\n",
    "    title2 = \"\"\n",
    "    m = re.search(r'(\\d+_weather)', filename)\n",
    "    if m:\n",
    "        title1 = m.group(1) + '_hours.csv'\n",
    "        title2 = m.group(1) + '_days.csv'\n",
    "    \n",
    "    \n",
    "    #this function cleans the weather csv and output 2 csv, one is for daily and one is for hour\n",
    "    df = pd.read_csv(filename,usecols=['DATE','HourlyWindSpeed','HourlyPrecipitation'])\n",
    "    #deal with missing value and special character\n",
    "    df = df.fillna(0)\n",
    "    df = df.replace('T',0)\n",
    "    df = df.replace('s','',regex = True)\n",
    "    #change the data type\n",
    "    df.DATE = pd.to_datetime(df.DATE)\n",
    "    df = df.astype({'HourlyPrecipitation':float,'HourlyWindSpeed':float})\n",
    "    df.set_index('DATE',drop = True).to_csv(title1)\n",
    "    df = df.resample('D', on='DATE').mean() \n",
    "    df = df.rename(mapper = {\"HourlyPrecipitation\":\"DailyPrecipitation\", \"HourlyWindSpeed\":\"DailyWindSpeed\"},axis = 1)\n",
    "    df.to_csv(title2)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2009,2016):\n",
    "    #create all weather data from 2009 to 2015\n",
    "    filename = str(i)+\"_weather.csv\"\n",
    "    create_weather_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Uber Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean uber sample data and makes the name consistent to the yellow taxi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber = pd.read_csv('uber_rides_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function gets the distance between two coordinates\n",
    "def get_distance(lon1,lat1,lon2,lat2):\n",
    "    from math import sin, cos, sqrt, atan2, radians\n",
    "    R = 6373\n",
    "    lon1 = radians(lon1)\n",
    "    lat1 = radians(lat1)\n",
    "    lon2 = radians(lon2)\n",
    "    lat2 = radians(lat2)\n",
    "    \n",
    "    dlon = lon1 - lon2\n",
    "    dlat = lat1 - lat2\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    \n",
    "    distance = R * c\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add distance to the dataframe with coordinates\n",
    "def add_distance(df):\n",
    "    distance = []\n",
    "    lon1 = list(df['pickup_longitude'])\n",
    "    lon2 = list(df['dropoff_longitude'])\n",
    "    lat1 = list(df['pickup_latitude'])\n",
    "    lat2 = list(df['dropoff_latitude'])\n",
    "    for i in range(len(lon1)):\n",
    "        distance.append(get_distance(lon1[i],lat1[i],lon2[i],lat2[i]))\n",
    "    df['distance']  = distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the clean version of uber dataframe\n",
    "def create_uber(df):\n",
    "    #clean uber data\n",
    "    df = df.rename(columns = lambda x: x.strip())\n",
    "   \n",
    "    #drop and rename column\n",
    "    to_drop = [\n",
    "        \"Unnamed: 0\",\n",
    "        \"key\",\n",
    "        \"passenger_count\"\n",
    "    ]\n",
    "    \n",
    "    mapper = {\n",
    "        \"pickup_datetime\" :\"pickup_time\",\n",
    "        \"fare_amount\" : \"charge\"\n",
    "    }\n",
    "    df = df.drop(to_drop, axis = 1,errors = \"ignore\")\n",
    "    df = df.rename(mapper, axis = 1)\n",
    "    df.dropna(inplace = True)\n",
    "    \n",
    "    #modify datatype\n",
    "    df = df.astype({\"pickup_time\":np.datetime64})\n",
    "    \n",
    "    \n",
    "    #add distance\n",
    "    add_distance(df)\n",
    "    df.to_csv('uber.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_uber(uber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Yellow Taxi Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find all csv files and filter them, then download as a dataframe and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_links():\n",
    "    #this function visitsï¼š https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\n",
    "    #It requests the source code on the website and get all the hrefs related to csv\n",
    "    #the urls are saved in link_lists\n",
    "    link_lists = []\n",
    "    url = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    aclasses = soup.find_all('a')\n",
    "    for a in aclasses:\n",
    "        link_lists.append(a.get('href'))\n",
    "    #Then we filter on link_lists using re because we only want to grab csv for yellow taxi ranging from 2009 - 2015.\n",
    "    csv_links = []\n",
    "    pattern = re.compile(r'.yellow_tripdata_(200[9]|201[0-5])-\\d\\d\\.csv$')\n",
    "    for i in link_lists:\n",
    "        if re.search(pattern,i):\n",
    "            csv_links.append(i)\n",
    "    return csv_links\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "westlimit=-74.242330; southlimit=40.560445; eastlimit=-73.717047; northlimit=40.908524\n",
    "#Remove the data that is not within the limits specified above\n",
    "\n",
    "def fix_longitude(input_longitude):\n",
    "    try:\n",
    "        input_longitude = float(input_longitude)\n",
    "    except:\n",
    "        return np.NaN\n",
    "    if input_longitude < westlimit or input_longitude > eastlimit:\n",
    "        return np.NaN\n",
    "    return input_longitude\n",
    "\n",
    "\n",
    "def fix_latitude(input_latitude):\n",
    "    try:\n",
    "        input_latitude = float(input_latitude)\n",
    "    except:\n",
    "        return np.NaN\n",
    "    if input_latitude < southlimit or input_latitude > northlimit:\n",
    "        return np.NaN\n",
    "    return input_latitude\n",
    "\n",
    "\n",
    "def fix_df(df):\n",
    "    df['pickup_longitude']=df['pickup_longitude'].apply(fix_longitude)\n",
    "    df['dropoff_longitude']=df['dropoff_longitude'].apply(fix_longitude)\n",
    "    df['pickup_latitude']=df['pickup_latitude'].apply(fix_latitude)\n",
    "    df['dropoff_latitude']=df['dropoff_latitude'].apply(fix_latitude)\n",
    "    df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(csv_link):\n",
    "   \n",
    "    # make sure the output title is consistent \n",
    "    title = \"\"\n",
    "    m = re.search(r'(yellow.+)', csv_link)\n",
    "    if m:\n",
    "        title = m.group(1)\n",
    "   \n",
    "    #read the data into a dataframe\n",
    "    df = pd.read_csv(csv_link,on_bad_lines='skip')\n",
    "    df = df.rename(columns = lambda x: x.strip())\n",
    "   \n",
    "    #drop and rename column\n",
    "    to_drop = [\n",
    "        \"Unnamed: 0\",\n",
    "        \"vendor_name\",\n",
    "        \"vendor_id\",\n",
    "        \"Vendor_id\",\n",
    "        'VendorID',\n",
    "        \"Trip_distance\",\n",
    "        \"Trip_Distance\",\n",
    "        \"trip_distance\",\n",
    "        \"Rate_Code\",\n",
    "        \"store_and_forward\",\n",
    "        \"store_and_fwd_flag\",\n",
    "        \"Payment_Type\",\n",
    "        \"Fare_Amt\",\n",
    "        \"surcharge\",\n",
    "        \"mta_tax\",\n",
    "        \"Tolls_Amt\",\n",
    "        \"rate_code\",\n",
    "        \"RatecodeID\",\n",
    "        \"RateCodeID\",\n",
    "        \"payment_type\",\n",
    "        \"fare_amount\",\n",
    "        \"extra\",\n",
    "        \"tolls_amount\",\n",
    "        \"improvement_surcharge\",\n",
    "        \"Passenger_Count\",\n",
    "        \"passenger_count\"\n",
    "    ]\n",
    "    \n",
    "    mapper = {\n",
    "        \"Trip_Pickup_DateTime\" : \"pickup_time\",\n",
    "        \"tpep_pickup_datetime\" : \"pickup_time\",\n",
    "        \"pickup_datetime\": \"pickup_time\",\n",
    "        \"dropoff_datetime\" : \"dropoff_time\",\n",
    "        \"Trip_Dropoff_DateTime\" : \"dropoff_time\",\n",
    "        \"tpep_dropoff_datetime\" : \"dropoff_time\",\n",
    "        \"Start_Lon\" : \"pickup_longitude\",\n",
    "        \"Start_Lat\" : \"pickup_latitude\",\n",
    "        \"End_Lon\" : \"dropoff_longitude\",\n",
    "        \"End_Lat\" : \"dropoff_latitude\",\n",
    "        \"Tip_Amt\" : 'tip',\n",
    "        \"tip_amount\" : \"tip\",\n",
    "        \"Total_Amt\" : \"charge\",\n",
    "        \"total_amount\" : \"charge\"\n",
    "    }\n",
    "    df = df.drop(to_drop, axis = 1,errors = \"ignore\")\n",
    "    df = df.rename(mapper, axis = 1)\n",
    "    df.dropna(inplace = True)\n",
    "    \n",
    "    #modify datatype\n",
    "    df = df.astype({\"pickup_time\":np.datetime64,\"dropoff_time\": np.datetime64})\n",
    "    \n",
    "    \n",
    "    #make sure the trip is within(40.560445, -74.242330) and (40.908524, -73.717047)\n",
    "    fix_df(df)\n",
    "    \n",
    "    #sample 3000 rows\n",
    "    df = df.sample(n=3000)\n",
    "    \n",
    "    #add distance\n",
    "    add_distance(df)\n",
    "    df.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    df.to_csv(title,index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run this to download all the yellow taxi sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "links = get_csv_links()\n",
    "for i in tqdm(range(len(links))):\n",
    "    create_csv(links[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first read all csv files into 4 dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createuber():\n",
    "    #this function reads in uber.csv and returns the data in pd.DataFrame format\n",
    "    uber = pd.read_csv('uber.csv')\n",
    "    uber.pickup_time = pd.to_datetime(uber.pickup_time)\n",
    "    uber = uber[uber.distance != 0]\n",
    "    return uber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createtaxi():\n",
    "    #this function reads in yellow_trip_{year}-{month}.csv and returns the data in pd.DataFrame format\n",
    "    filenames = []\n",
    "    for i in range(2009,2016):\n",
    "        for j in range(1,13):\n",
    "            if j <10:\n",
    "                filename = f'yellow_tripdata_{i}-0{j}.csv'\n",
    "                filenames.append(filename)\n",
    "            else:\n",
    "                filename = f'yellow_tripdata_{i}-{j}.csv'\n",
    "                filenames.append(filename)\n",
    "    taxi = pd.read_csv('yellow_tripdata_2009-01.csv',usecols = ['pickup_time','dropoff_time','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','charge','tip','distance'],nrows = 2314)\n",
    "    for i in range(1,len(filenames)):\n",
    "        df = pd.read_csv(filenames[i],usecols = ['pickup_time','dropoff_time','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','charge','tip','distance'], nrows = 2314)\n",
    "        taxi = pd.concat([taxi,df])\n",
    "    taxi.reset_index(inplace = True, drop = True)\n",
    "    taxi.pickup_time = pd.to_datetime(taxi.pickup_time)\n",
    "    taxi.dropoff_time = pd.to_datetime(taxi.dropoff_time)\n",
    "    return taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createhourlyweather():\n",
    "    #this function reads in {year}_weather_hours.csv and returns the data in pd.DataFrame format\n",
    "    filenames = []\n",
    "    for i in range(2009,2016):\n",
    "        filenames.append(f'{i}_weather_hours.csv')\n",
    "    weather_hourly = pd.read_csv('2009_weather_hours.csv')\n",
    "    for i in range(1,len(filenames)):\n",
    "        df = pd.read_csv(filenames[i])\n",
    "        weather_hourly = pd.concat([weather_hourly,df])\n",
    "    weather_hourly.reset_index(inplace = True, drop = True)\n",
    "    weather_hourly.DATE = pd.to_datetime(weather_hourly.DATE)\n",
    "    weather_hourly['DATE'] = weather_hourly['DATE'].dt.floor('H')\n",
    "    weather_hourly = weather_hourly.drop_duplicates('DATE',keep = 'first')\n",
    "    mapper = {'DATE': 'date', \"HourlyPrecipitation\":'precipitation','HourlyWindSpeed':'windspeed'}\n",
    "    weather_hourly = weather_hourly.rename(mapper,axis = 1)\n",
    "    return weather_hourly\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdailyweather():\n",
    "    #this function reads in {year}_weather_days.csv and returns the data in pd.DataFrame format\n",
    "    filenames = []\n",
    "    for i in range(2009,2016):\n",
    "        filenames.append(f'{i}_weather_days.csv')\n",
    "    weather_daily = pd.read_csv('2009_weather_days.csv')\n",
    "    for i in range(1,len(filenames)):\n",
    "        df = pd.read_csv(filenames[i])\n",
    "        weather_daily = pd.concat([weather_daily,df])\n",
    "    weather_daily.reset_index(inplace = True, drop = True)\n",
    "    weather_daily.DATE = pd.to_datetime(weather_daily.DATE)\n",
    "    mapper = {'DATE': 'date', \"DailyPrecipitation\":'precipitation','DailyWindSpeed':'windspeed'}\n",
    "    weather_daily = weather_daily.rename(mapper,axis = 1)\n",
    "    return weather_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber = createuber()\n",
    "taxi = createtaxi()\n",
    "weather_hourly= createhourlyweather()\n",
    "weather_daily = createdailyweather()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to build database and four tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sqlalchemy] BEGIN (implicit)\n",
      "[sqlalchemy] COMMIT\n"
     ]
    }
   ],
   "source": [
    "#build database\n",
    "engine = create_engine(f\"sqlite:///ubertaxi.db\", echo=True)\n",
    "sqllogger = logging.getLogger(\"sqlalchemy.engine.Engine\")\n",
    "formatter = logging.Formatter(\"[sqlalchemy] %(message)s\")\n",
    "sqllogger.handlers[0].setFormatter(formatter)\n",
    "Base = declarative_base()\n",
    "Base.metadata.create_all(engine, checkfirst=True)\n",
    "# sessionmaker returns a Session class\n",
    "Session = sessionmaker(bind=engine)\n",
    "# and we create an instance of Session\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readsqlfile(filename):\n",
    "    #I am gonna be honest, I found this on stack overflow. Basically it allows the sqlalchemy to execute multiple queries \n",
    "    #in one file. \n",
    "    sql_file = open('schema.sql','r')\n",
    "\n",
    "    # Create an empty command string\n",
    "    sql_command = ''\n",
    "    for line in sql_file:\n",
    "        # Ignore commented lines\n",
    "        if not line.startswith('--') and line.strip('\\n'):\n",
    "            # Append line to the command string\n",
    "            sql_command += line.strip('\\n')\n",
    "            # If the command string ends with ';', it is a full statement\n",
    "            if sql_command.endswith(';'):\n",
    "                # Try to execute statement and commit it\n",
    "                try:\n",
    "                    session.execute(text(sql_command))\n",
    "                    session.commit()\n",
    "                # Assert in case of error\n",
    "                except:\n",
    "                    print('Ops')\n",
    "                # Finally, clear command string\n",
    "                finally:\n",
    "                    sql_command = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read schema file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sqlalchemy] BEGIN (implicit)\n",
      "[sqlalchemy] CREATE TABLE weather_daily(date Datetime,precipitation FLOAT,windspeed FLOAT);\n",
      "[sqlalchemy] [generated in 0.00296s] ()\n",
      "Ops\n",
      "[sqlalchemy] CREATE TABLE weather_hourly(date Datetime,precipitation FLOAT,windspeed FLOAT);\n",
      "[sqlalchemy] [generated in 0.00188s] ()\n",
      "Ops\n",
      "[sqlalchemy] CREATE TABLE yellow_taxi(pickup_time DATETIME,dropoff_time DATETIME,pickup_longitude FLOAT,pickup_latitude FLOAT,dropoff_longitude FLOAT,dropoff_latitude FLOAT,tip FLOAT,charge FLOAT,distance FLOAT);\n",
      "[sqlalchemy] [generated in 0.00154s] ()\n",
      "Ops\n",
      "[sqlalchemy] CREATE TABLE Uber(charge FLOAT,pickup_time DATETIME,pickup_longitude FLOAT,dropoff_longitude FLOAT,pickup_latitude FLOAT,dropoff_latitude FLOAT,distance FLOAT);\n",
      "[sqlalchemy] [generated in 0.00173s] ()\n",
      "Ops\n"
     ]
    }
   ],
   "source": [
    "readsqlfile('schema.sql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sqlalchemy] PRAGMA main.table_info(\"Uber\")\n",
      "[sqlalchemy] [raw sql] ()\n",
      "[sqlalchemy] PRAGMA temp.table_info(\"Uber\")\n",
      "[sqlalchemy] [raw sql] ()\n",
      "[sqlalchemy] BEGIN (implicit)\n",
      "[sqlalchemy] \n",
      "CREATE TABLE \"Uber\" (\n",
      "\tcharge FLOAT, \n",
      "\tpickup_time DATETIME, \n",
      "\tpickup_longitude FLOAT, \n",
      "\tpickup_latitude FLOAT, \n",
      "\tdropoff_longitude FLOAT, \n",
      "\tdropoff_latitude FLOAT, \n",
      "\tdistance FLOAT\n",
      ")\n",
      "\n",
      "\n",
      "[sqlalchemy] [no key 0.00068s] ()\n",
      "[sqlalchemy] COMMIT\n",
      "[sqlalchemy] BEGIN (implicit)\n",
      "[sqlalchemy] INSERT INTO \"Uber\" (charge, pickup_time, pickup_longitude, pickup_latitude, dropoff_longitude, dropoff_latitude, distance) VALUES (?, ?, ?, ?, ?, ?, ?)\n",
      "[sqlalchemy] [generated in 1.76549s] ((7.5, '2015-05-07 19:52:06.000000', -73.99981689453125, 40.73835372924805, -73.99951171875, 40.72321701049805, 1.6838511852242786), (7.7, '2009-07-17 20:04:56.000000', -73.994355, 40.728225, -73.99471, 40.750325, 2.458361376443877), (12.9, '2009-08-24 21:45:00.000000', -74.005043, 40.74077, -73.962565, 40.772647, 5.0379582221658445), (5.3, '2009-06-26 08:22:21.000000', -73.976124, 40.790844, -73.965316, 40.803349, 1.6622050981962735), (16.0, '2014-08-28 17:47:00.000000', -73.925023, 40.744085, -73.97308199999999, 40.761247, 4.4768549072953325), (24.5, '2014-10-12 07:04:00.000000', -73.96144699999999, 40.693965000000006, -73.871195, 40.774297, 11.734697512602486), (9.7, '2012-02-17 09:32:00.000000', -73.975187, 40.745767, -74.00272, 40.743537, 2.333443299721285), (12.5, '2012-03-29 19:06:00.000000', -74.001065, 40.741787, -73.96304, 40.775012, 4.890951785888044)  ... displaying 10 of 194367 total bound parameter sets ...  (14.5, '2015-05-20 14:56:25.000000', -73.99712371826173, 40.7254524230957, -73.98321533203125, 40.69541549682617, 3.5408266479309387), (14.1, '2010-05-15 04:08:00.000000', -73.98439499999999, 40.720077, -73.985508, 40.768793, 5.419484244981255))\n",
      "[sqlalchemy] COMMIT\n",
      "[sqlalchemy] SELECT name FROM sqlite_master WHERE type='table' ORDER BY name\n",
      "[sqlalchemy] [raw sql] ()\n",
      "[sqlalchemy] PRAGMA main.table_info(\"yellow_taxi\")\n",
      "[sqlalchemy] [raw sql] ()\n",
      "[sqlalchemy] PRAGMA temp.table_info(\"yellow_taxi\")\n",
      "[sqlalchemy] [raw sql] ()\n",
      "[sqlalchemy] BEGIN (implicit)\n",
      "[sqlalchemy] \n",
      "CREATE TABLE yellow_taxi (\n",
      "\tpickup_time DATETIME, \n",
      "\tdropoff_time DATETIME, \n",
      "\tpickup_longitude FLOAT, \n",
      "\tpickup_latitude FLOAT, \n",
      "\tdropoff_longitude FLOAT, \n",
      "\tdropoff_latitude FLOAT, \n",
      "\ttip FLOAT, \n",
      "\tcharge FLOAT, \n",
      "\tdistance FLOAT\n",
      ")\n",
      "\n",
      "\n",
      "[sqlalchemy] [no key 0.00061s] ()\n",
      "[sqlalchemy] COMMIT\n",
      "[sqlalchemy] BEGIN (implicit)\n",
      "[sqlalchemy] INSERT INTO yellow_taxi (pickup_time, dropoff_time, pickup_longitude, pickup_latitude, dropoff_longitude, dropoff_latitude, tip, charge, distance) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
      "[sqlalchemy] [generated in 2.44100s] (('2009-01-10 22:00:53.000000', '2009-01-10 22:12:59.000000', -73.985455, 40.735604, -73.980652, 40.763299, 0.5999999999999999, 10.0, 3.106983034371679), ('2009-01-20 17:50:03.000000', '2009-01-20 18:11:48.000000', -73.946053, 40.775474, -73.982416, 40.764801, 0.0, 13.5, 3.285159434004516), ('2009-01-05 11:27:15.000000', '2009-01-05 11:40:23.000000', -73.96777199999998, 40.786988, -73.95498, 40.76623, 0.0, 9.3, 2.547941290711391), ('2009-01-03 12:01:37.000000', '2009-01-03 12:05:31.000000', -73.979783, 40.7572, -73.973967, 40.766057, 0.0, 4.5, 1.1002900803175624), ('2009-01-18 01:01:06.000000', '2009-01-18 01:06:11.000000', -73.973095, 40.744304, -73.95614899999998, 40.771973, 0.0, 7.4, 3.3926733836607244), ('2009-01-06 00:07:16.000000', '2009-01-06 00:23:58.000000', -73.874791, 40.774081, -73.953866, 40.818769, 0.0, 23.15, 8.30920976716833), ('2009-01-17 14:38:00.000000', '2009-01-17 14:51:00.000000', -74.003163, 40.731217, -74.01419199999998, 40.717087, 0.0, 8.5, 1.8260682409046776), ('2009-01-18 02:22:00.000000', '2009-01-18 02:26:00.000000', -74.000253, 40.737798, -74.000253, 40.737798, 0.0, 4.6, 0.0)  ... displaying 10 of 194376 total bound parameter sets ...  ('2015-12-16 16:54:54.000000', '2015-12-16 16:57:34.000000', -73.94960021972656, 40.77705001831056, -73.95596313476561, 40.77965927124024, 0.4, 6.2, 0.609473353061974), ('2015-12-23 22:34:02.000000', '2015-12-23 22:39:05.000000', -73.97403717041014, 40.762657165527344, -73.97759246826173, 40.7539176940918, 0.0, 6.3, 1.0171953963618967))\n",
      "[sqlalchemy] COMMIT\n",
      "[sqlalchemy] PRAGMA main.table_info(\"weather_hourly\")\n",
      "[sqlalchemy] [raw sql] ()\n",
      "[sqlalchemy] PRAGMA temp.table_info(\"weather_hourly\")\n",
      "[sqlalchemy] [raw sql] ()\n",
      "[sqlalchemy] BEGIN (implicit)\n",
      "[sqlalchemy] \n",
      "CREATE TABLE weather_hourly (\n",
      "\tdate DATETIME, \n",
      "\tprecipitation FLOAT, \n",
      "\twindspeed FLOAT\n",
      ")\n",
      "\n",
      "\n",
      "[sqlalchemy] [no key 0.00052s] ()\n",
      "[sqlalchemy] COMMIT\n",
      "[sqlalchemy] BEGIN (implicit)\n",
      "[sqlalchemy] INSERT INTO weather_hourly (date, precipitation, windspeed) VALUES (?, ?, ?)\n",
      "[sqlalchemy] [generated in 0.34296s] (('2009-01-01 00:00:00.000000', 0.0, 18.0), ('2009-01-01 01:00:00.000000', 0.0, 18.0), ('2009-01-01 02:00:00.000000', 0.0, 18.0), ('2009-01-01 03:00:00.000000', 0.0, 8.0), ('2009-01-01 04:00:00.000000', 0.0, 11.0), ('2009-01-01 05:00:00.000000', 0.0, 18.0), ('2009-01-01 06:00:00.000000', 0.0, 14.0), ('2009-01-01 07:00:00.000000', 0.0, 8.0)  ... displaying 10 of 60458 total bound parameter sets ...  ('2015-12-31 22:00:00.000000', 0.0, 7.0), ('2015-12-31 23:00:00.000000', 0.0, 5.0))\n",
      "[sqlalchemy] COMMIT\n",
      "[sqlalchemy] PRAGMA main.table_info(\"weather_daily\")\n",
      "[sqlalchemy] [raw sql] ()\n",
      "[sqlalchemy] PRAGMA temp.table_info(\"weather_daily\")\n",
      "[sqlalchemy] [raw sql] ()\n",
      "[sqlalchemy] BEGIN (implicit)\n",
      "[sqlalchemy] \n",
      "CREATE TABLE weather_daily (\n",
      "\tdate DATETIME, \n",
      "\tprecipitation FLOAT, \n",
      "\twindspeed FLOAT\n",
      ")\n",
      "\n",
      "\n",
      "[sqlalchemy] [no key 0.00090s] ()\n",
      "[sqlalchemy] COMMIT\n",
      "[sqlalchemy] BEGIN (implicit)\n",
      "[sqlalchemy] INSERT INTO weather_daily (date, precipitation, windspeed) VALUES (?, ?, ?)\n",
      "[sqlalchemy] [generated in 0.01494s] (('2009-01-01 00:00:00.000000', 0.0, 11.041666666666666), ('2009-01-02 00:00:00.000000', 0.0, 6.59375), ('2009-01-03 00:00:00.000000', 0.0, 9.875), ('2009-01-04 00:00:00.000000', 0.0, 7.37037037037037), ('2009-01-05 00:00:00.000000', 0.0, 6.925925925925926), ('2009-01-06 00:00:00.000000', 0.004, 6.9), ('2009-01-07 00:00:00.000000', 0.0466666666666666, 9.58974358974359), ('2009-01-08 00:00:00.000000', 0.0, 11.192307692307692)  ... displaying 10 of 2556 total bound parameter sets ...  ('2015-12-30 00:00:00.000000', 0.0074358974358974, 4.076923076923077), ('2015-12-31 00:00:00.000000', 0.0022857142857142, 4.2))\n",
      "[sqlalchemy] COMMIT\n"
     ]
    }
   ],
   "source": [
    "#add four dataframes into sql tables\n",
    "#DONT EXECUTE TWINCE!!!!!\n",
    "'''\n",
    "uber.to_sql('Uber', engine, if_exists='append',index = False)\n",
    "taxi.to_sql('yellow_taxi', engine, if_exists='append',index = False)\n",
    "weather_hourly.to_sql('weather_hourly', engine, if_exists='append',index = False)\n",
    "weather_daily.to_sql('weather_daily', engine, if_exists='append',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sqlalchemy] SELECT COUNT(*) FROM yellow_taxi\n",
      "[sqlalchemy] [raw sql] ()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(194376,)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(\"SELECT COUNT(*) FROM yellow_taxi\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specifically for the file that only contains one command\n",
    "def readsql(filename):\n",
    "    with engine.connect() as con:\n",
    "        with open(filename) as file:\n",
    "            query = text(file.read())\n",
    "            return engine.execute(query).fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 01-2009 through 06-2015, what hour of the day was the most popular to take a Yellow Taxi? The result should have 24 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sqlalchemy] SELECT \n",
      "strftime ('%H',pickup_time) as most_popular_hour,\n",
      "Count(*) as times\n",
      "FROM\n",
      "yellow_taxi\n",
      "WHERE\n",
      "pickup_time between '2009-01-01' AND '2015-06-30'\n",
      "GROUP BY strftime ('%H',pickup_time) \n",
      "ORDER BY times DESC\n",
      "LIMIT 1;\n",
      "[sqlalchemy] [generated in 0.00171s] ()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('19', 11260)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readsql('most_popular_hour.sql')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the same time frame, what day of the week was the most popular to take an Uber? The result should have 7 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sqlalchemy] SELECT \n",
      "strftime ('%w',pickup_time) as most_popular_day,\n",
      "Count(*) as times\n",
      "FROM\n",
      "Uber\n",
      "WHERE\n",
      "pickup_time between '2009-01-01' AND '2015-06-30'\n",
      "GROUP BY strftime ('%w',pickup_time) \n",
      "ORDER BY times DESC\n",
      "LIMIT 1;\n",
      "[sqlalchemy] [generated in 0.00133s] ()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('5', 29996)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readsql('most_popular_day.sql')\n",
    "#So it is Friday! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "temp1 = pd.concat([uber.loc[:,['pickup_time','distance']],\n",
    "          taxi.loc[:,['pickup_time','distance']]],axis=0)\n",
    "temp = temp1.loc[(temp1['pickup_time']<='2013-07-31')&(temp1['pickup_time']>='2013-07-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.511437894197023"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(temp.distance,95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## why sql output deos not equals to python output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the 95% percentile of distance traveled for all hired trips during July 2013?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sqlalchemy] select \n",
      "t_1.distance as '95percentile'\n",
      "\n",
      "from \n",
      "\n",
      "(\n",
      "select \n",
      "distance\n",
      "\n",
      "from \n",
      "yellow_taxi\n",
      "\n",
      "where \n",
      "pickup_time between '2013-07-01' and '2013-07-31'\n",
      "\n",
      "union \n",
      "\n",
      "select \n",
      "distance\n",
      "\n",
      "from \n",
      "Uber\n",
      "\n",
      "where \n",
      "pickup_time between '2013-07-01' and '2013-07-31'\n",
      "\n",
      ")t_1\n",
      "\n",
      "order by t_1.distance asc\n",
      "\n",
      "limit 1\n",
      "\n",
      "offset \n",
      "\n",
      "(select\n",
      "\n",
      "count(*)\n",
      "\n",
      "from \n",
      "\n",
      "(select \n",
      "distance\n",
      "\n",
      "from \n",
      "yellow_taxi\n",
      "\n",
      "where \n",
      "pickup_time between '2013-07-01' and '2013-07-31'\n",
      "\n",
      "union \n",
      "\n",
      "select \n",
      "distance\n",
      "\n",
      "from \n",
      "Uber\n",
      "\n",
      "where \n",
      "pickup_time between '2013-07-01' and '2013-07-31'\n",
      "\n",
      ")\n",
      "\n",
      ") * 95 / 100 -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[sqlalchemy] [generated in 0.00201s] ()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(10.51429989869938,)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readsql('95distance.sql')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What were the top 10 days with the highest number of hired rides for 2009, and what was the average distance for each day?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sqlalchemy] \n",
      "select \n",
      "t_1.date as date,\n",
      "t_1.sum_distance/t_1.total_trips as avg_distance\n",
      "\n",
      "from \n",
      "\n",
      "(select \n",
      "\n",
      "t_0.date as date,\n",
      "sum(t_0.total_trips) as total_trips,\n",
      "sum(t_0.sum_distance) as sum_distance\n",
      "\n",
      "from \n",
      "\n",
      "(select \n",
      "strftime ('%Y-%m-%d',pickup_time) as date,\n",
      "count(*) as total_trips,\n",
      "sum(distance) as sum_distance\n",
      "\n",
      "from \n",
      "yellow_taxi\n",
      "\n",
      "where \n",
      "pickup_time between '2009-01-01' and '2009-12-31'\n",
      "\n",
      "group by \n",
      "strftime ('%Y-%m-%d',pickup_time)\n",
      "\n",
      "union \n",
      "\n",
      "select \n",
      "strftime ('%Y-%m-%d',pickup_time) as date,\n",
      "count(*) as total_trips,\n",
      "sum(distance) as sum_distance\n",
      "\n",
      "from \n",
      "Uber\n",
      "\n",
      "where \n",
      "pickup_time between '2009-01-01' and '2009-12-31'\n",
      "\n",
      "group by \n",
      "strftime ('%Y-%m-%d',pickup_time)\n",
      "\n",
      ")t_0\n",
      "\n",
      "group by \n",
      "t_0.date \n",
      "\n",
      ")t_1\n",
      "\n",
      "group by \n",
      "t_1.date\n",
      "\n",
      "order by \n",
      "sum(t_1.total_trips) desc\n",
      "\n",
      "limit 10\n",
      "\n",
      "[sqlalchemy] [generated in 0.00685s] ()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('2009-02-20', 3.263599853629076),\n",
       " ('2009-01-31', 3.1723376976203603),\n",
       " ('2009-10-23', 3.0628925035762635),\n",
       " ('2009-12-11', 2.91146117591069),\n",
       " ('2009-04-04', 2.776783009971279),\n",
       " ('2009-04-18', 3.162042435346948),\n",
       " ('2009-08-14', 3.3734259374996878),\n",
       " ('2009-04-16', 3.1843847137729346),\n",
       " ('2009-09-10', 3.047313220759373),\n",
       " ('2009-12-05', 3.029545346863909)]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readsql('top10days.sql')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which 10 days in 2014 were the windiest on average, and how many hired trips were made on those days?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sqlalchemy] \n",
      "select \n",
      "t_1.date as date,\n",
      "sum(t_2.total_trips) as total_trips\n",
      "\n",
      "from \n",
      "\n",
      "(select \n",
      "strftime ('%Y-%m-%d',date) as date,\n",
      "windspeed\n",
      "\n",
      "from \n",
      "weather_daily\n",
      "\n",
      "where \n",
      "date between '2014-01-01' and '2014-12-31'\n",
      ")t_1\n",
      "\n",
      "left join \n",
      "\n",
      "(select \n",
      "strftime ('%Y-%m-%d',pickup_time) as date,\n",
      "count(*) as total_trips\n",
      "\n",
      "from \n",
      "yellow_taxi\n",
      "\n",
      "where \n",
      "pickup_time between '2014-01-01' and '2014-12-31'\n",
      "\n",
      "group by \n",
      "strftime ('%Y-%m-%d',pickup_time)\n",
      "\n",
      "union \n",
      "\n",
      "select \n",
      "strftime ('%Y-%m-%d',pickup_time) as date,\n",
      "count(*) as total_trips\n",
      "\n",
      "from \n",
      "Uber\n",
      "\n",
      "where \n",
      "pickup_time between '2014-01-01' and '2014-12-31'\n",
      "\n",
      "group by \n",
      "strftime ('%Y-%m-%d',pickup_time)\n",
      ")t_2\n",
      "\n",
      "on \n",
      "t_1.date = t_2.date\n",
      "\n",
      "group by \n",
      "t_1.date\n",
      "\n",
      "order by \n",
      "t_1.windspeed desc \n",
      "\n",
      "limit 10\n",
      "\n",
      "\n",
      "\n",
      "[sqlalchemy] [generated in 0.00154s] ()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('2014-03-13', 192),\n",
       " ('2014-01-07', 147),\n",
       " ('2014-01-02', 117),\n",
       " ('2014-02-13', 116),\n",
       " ('2014-03-29', 202),\n",
       " ('2014-12-07', 165),\n",
       " ('2014-12-09', 154),\n",
       " ('2014-12-08', 159),\n",
       " ('2014-03-26', 175),\n",
       " ('2014-01-03', 85)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readsql('top10windspeed.sql')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During Hurricane Sandy in NYC (Oct 29-30, 2012), plus the week leading up and the week after, how many trips were taken each hour, and for each hour, how much precipitation did NYC receive and what was the sustained wind speed? There should be an entry for every single hour, even if no rides were taken, no precipitation was measured, or there was no wind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what's the dimension?  [date,hour] or hour\n",
    "#if it is hour, then precipitation should be summed? wind speed should be averaged?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp0 = temp1.groupby(['hour']).agg({'precipitation': 'sum', 'windspeed': 'mean'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = pd.concat([uber.loc[:,['pickup_time']],\n",
    "          taxi.loc[:,['pickup_time']]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = temp2.loc[(temp2['pickup_time']>='2012-10-22')&(temp2['pickup_time']<='2012-11-06')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuanshuqing/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "temp2['hour'] = temp2['pickup_time'].apply(lambda x: x.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = temp2.groupby('hour').count().reset_index().rename(columns={'pickup_time':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>5.937500</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.03</td>\n",
       "      <td>4.933333</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.04</td>\n",
       "      <td>6.066667</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5.066667</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.02</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6.733333</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6.866667</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.02</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.266667</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.02</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.02</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6.733333</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.07</td>\n",
       "      <td>6.466667</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.11</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.02</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.02</td>\n",
       "      <td>5.533333</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.03</td>\n",
       "      <td>5.533333</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.03</td>\n",
       "      <td>4.933333</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hour  precipitation  windspeed  count\n",
       "0      0           0.03   5.937500     76\n",
       "1      1           0.01   5.333333     58\n",
       "2      2           0.03   4.933333     59\n",
       "3      3           0.04   6.066667     31\n",
       "4      4           0.00   5.800000     31\n",
       "5      5           0.01   5.066667     28\n",
       "6      6           0.03   6.666667     36\n",
       "7      7           0.02   5.000000     71\n",
       "8      8           0.01   6.733333     76\n",
       "9      9           0.01   6.866667     94\n",
       "10    10           0.02   4.666667     82\n",
       "11    11           0.00   6.266667    109\n",
       "12    12           0.02   7.800000     87\n",
       "13    13           0.02   6.800000    107\n",
       "14    14           0.03   6.733333     99\n",
       "15    15           0.07   6.466667    109\n",
       "16    16           0.11   6.600000     75\n",
       "17    17           0.04   7.500000    123\n",
       "18    18           0.02   6.666667    122\n",
       "19    19           0.01   6.800000    126\n",
       "20    20           0.02   5.533333    136\n",
       "21    21           0.00   6.800000    120\n",
       "22    22           0.03   5.533333    119\n",
       "23    23           0.03   4.933333     82"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp0.merge(temp2,on = ['hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sqlalchemy] \n",
      "select \n",
      "t_1.hour as hour,\n",
      "t_1.sum_precipitation as sum_precipitation,\n",
      "t_1.avg_windspeed as avg_windspeed,\n",
      "sum(t_2.total_trips) as total_trips\n",
      "\n",
      "from \n",
      "\n",
      "(select \n",
      "strftime ('%H',date) as hour,\n",
      "sum(precipitation) as sum_precipitation,\n",
      "avg(windspeed) as avg_windspeed\n",
      "\n",
      "from\n",
      "weather_hourly \n",
      "\n",
      "where \n",
      "date between '2012-10-22' and '2012-11-06'\n",
      "\n",
      "group by \n",
      "strftime ('%H',date) \n",
      ")t_1\n",
      "\n",
      "left join \n",
      "\n",
      "(select \n",
      "strftime ('%H',pickup_time) as hour,\n",
      "count(*) as total_trips\n",
      "\n",
      "from \n",
      "yellow_taxi\n",
      "\n",
      "where \n",
      "pickup_time between '2012-10-22' and '2012-11-06'\n",
      "\n",
      "group by \n",
      "strftime ('%H',pickup_time)\n",
      "\n",
      "union \n",
      "\n",
      "select \n",
      "strftime ('%H',pickup_time) as hour,\n",
      "count(*) as total_trips\n",
      "\n",
      "from \n",
      "Uber\n",
      "\n",
      "where \n",
      "pickup_time between '2012-10-22' and '2012-11-06'\n",
      "\n",
      "group by \n",
      "strftime ('%H',pickup_time)\n",
      "\n",
      ")t_2\n",
      "\n",
      "on \n",
      "t_1.hour = t_2.hour\n",
      "\n",
      "group by \n",
      "t_1.hour,\n",
      "t_1.sum_precipitation,\n",
      "t_1.avg_windspeed\n",
      "\n",
      "\n",
      "\n",
      "[sqlalchemy] [generated in 0.00186s] ()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('00', 0.03, 5.933333333333334, 76),\n",
       " ('01', 0.01, 5.333333333333333, 58),\n",
       " ('02', 0.03, 4.933333333333334, 59),\n",
       " ('03', 0.04, 6.066666666666666, 31),\n",
       " ('04', 0.0, 5.8, 31),\n",
       " ('05', 0.01, 5.066666666666666, 28),\n",
       " ('06', 0.03, 6.666666666666667, 36),\n",
       " ('07', 0.02, 5.0, 71),\n",
       " ('08', 0.01, 6.733333333333333, 76),\n",
       " ('09', 0.01, 6.866666666666666, 94),\n",
       " ('10', 0.02, 4.666666666666667, 82),\n",
       " ('11', 0.0, 6.266666666666667, 109),\n",
       " ('12', 0.02, 7.8, 87),\n",
       " ('13', 0.02, 6.8, 107),\n",
       " ('14', 0.03, 6.733333333333333, 99),\n",
       " ('15', 0.07, 6.466666666666667, 109),\n",
       " ('16', 0.11, 6.6, 75),\n",
       " ('17', 0.04, 7.5, 123),\n",
       " ('18', 0.02, 6.666666666666667, 122),\n",
       " ('19', 0.01, 6.8, 126),\n",
       " ('20', 0.02, 5.533333333333333, 136),\n",
       " ('21', 0.0, 6.8, 120),\n",
       " ('22', 0.03, 5.533333333333333, 119),\n",
       " ('23', 0.03, 4.933333333333334, 82)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readsql('hurricane_hourly.sql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
