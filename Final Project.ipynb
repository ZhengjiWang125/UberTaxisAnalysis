{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dab45e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edfc28a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbdc020",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd35f21",
   "metadata": {},
   "source": [
    "Running this part will download all the files in the local repo, but it will take a long time. \n",
    "Depending on the machine it runs on, it might throw error due to large size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25e908d",
   "metadata": {},
   "source": [
    "### Clean Weather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da62b602",
   "metadata": {},
   "source": [
    "All weather csv are cleaned and seperated into hours part and days part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60298343",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the clean version of weather csv and seprated into two parts\n",
    "def create_weather_csv(filename):\n",
    "    # make sure the output title is consistent \n",
    "    title1 = \"\"\n",
    "    title2 = \"\"\n",
    "    m = re.search(r'(\\d+_weather)', filename)\n",
    "    if m:\n",
    "        title1 = m.group(1) + '_hours.csv'\n",
    "        title2 = m.group(1) + '_days.csv'\n",
    "    \n",
    "    \n",
    "    #this function cleans the weather csv and output 2 csv, one is for daily and one is for hour\n",
    "    df = pd.read_csv(filename,usecols=['DATE','HourlyWindSpeed','HourlyPrecipitation'])\n",
    "    #deal with missing value and special character\n",
    "    df = df.fillna(0)\n",
    "    df = df.replace('T',0)\n",
    "    df = df.replace('s','',regex = True)\n",
    "    #change the data type\n",
    "    df.DATE = pd.to_datetime(df.DATE)\n",
    "    df = df.astype({'HourlyPrecipitation':float,'HourlyWindSpeed':float})\n",
    "    df.set_index('DATE',drop = True).to_csv(title1)\n",
    "    df = df.resample('D', on='DATE').mean() \n",
    "    df = df.rename(mapper = {\"HourlyPrecipitation\":\"DailyPrecipitation\", \"HourlyWindSpeed\":\"DailyWindSpeed\"},axis = 1)\n",
    "    df.to_csv(title2)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a61e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2009,2016):\n",
    "    #create all weather data from 2009 to 2015\n",
    "    filename = str(i)+\"_weather.csv\"\n",
    "    create_weather_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e363d2",
   "metadata": {},
   "source": [
    "### Clean Uber Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f862a1",
   "metadata": {},
   "source": [
    "Clean uber sample data and makes the name consistent to the yellow taxi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabe5081",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber = pd.read_csv('uber_rides_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b72b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function gets the distance between two coordinates\n",
    "def get_distance(lon1,lat1,lon2,lat2):\n",
    "    from math import sin, cos, sqrt, atan2, radians\n",
    "    R = 6373\n",
    "    lon1 = radians(lon1)\n",
    "    lat1 = radians(lat1)\n",
    "    lon2 = radians(lon2)\n",
    "    lat2 = radians(lat2)\n",
    "    \n",
    "    dlon = lon1 - lon2\n",
    "    dlat = lat1 - lat2\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    \n",
    "    distance = R * c\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b835f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add distance to the dataframe with coordinates\n",
    "def add_distance(df):\n",
    "    distance = []\n",
    "    lon1 = list(df['pickup_longitude'])\n",
    "    lon2 = list(df['dropoff_longitude'])\n",
    "    lat1 = list(df['pickup_latitude'])\n",
    "    lat2 = list(df['dropoff_latitude'])\n",
    "    for i in range(len(lon1)):\n",
    "        distance.append(get_distance(lon1[i],lat1[i],lon2[i],lat2[i]))\n",
    "    df['distance']  = distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40562a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the clean version of uber dataframe\n",
    "def create_uber(df):\n",
    "    #clean uber data\n",
    "    df = df.rename(columns = lambda x: x.strip())\n",
    "   \n",
    "    #drop and rename column\n",
    "    to_drop = [\n",
    "        \"Unnamed: 0\",\n",
    "        \"key\",\n",
    "        \"passenger_count\"\n",
    "    ]\n",
    "    \n",
    "    mapper = {\n",
    "        \"pickup_datetime\" :\"pickup_time\",\n",
    "        \"fare_amount\" : \"charge\"\n",
    "    }\n",
    "    df = df.drop(to_drop, axis = 1,errors = \"ignore\")\n",
    "    df = df.rename(mapper, axis = 1)\n",
    "    df.dropna(inplace = True)\n",
    "    \n",
    "    #modify datatype\n",
    "    df = df.astype({\"pickup_time\":np.datetime64})\n",
    "    \n",
    "    \n",
    "    #add distance\n",
    "    add_distance(df)\n",
    "    df.to_csv('uber.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cd75b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_uber(uber)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc180a4",
   "metadata": {},
   "source": [
    "### Clean Yellow Taxi Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390472d4",
   "metadata": {},
   "source": [
    "find all csv files and filter them, then download as a dataframe and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a692d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_links():\n",
    "    #this function visitsï¼š https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\n",
    "    #It requests the source code on the website and get all the hrefs related to csv\n",
    "    #the urls are saved in link_lists\n",
    "    link_lists = []\n",
    "    url = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    aclasses = soup.find_all('a')\n",
    "    for a in aclasses:\n",
    "        link_lists.append(a.get('href'))\n",
    "    #Then we filter on link_lists using re because we only want to grab csv for yellow taxi ranging from 2009 - 2015.\n",
    "    csv_links = []\n",
    "    pattern = re.compile(r'.yellow_tripdata_(200[9]|201[0-5])-\\d\\d\\.csv$')\n",
    "    for i in link_lists:\n",
    "        if re.search(pattern,i):\n",
    "            csv_links.append(i)\n",
    "    return csv_links\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f111f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "westlimit=-74.242330; southlimit=40.560445; eastlimit=-73.717047; northlimit=40.908524\n",
    "#Remove the data that is not within the limits specified above\n",
    "\n",
    "def fix_longitude(input_longitude):\n",
    "    try:\n",
    "        input_longitude = float(input_longitude)\n",
    "    except:\n",
    "        return np.NaN\n",
    "    if input_longitude < westlimit or input_longitude > eastlimit:\n",
    "        return np.NaN\n",
    "    return input_longitude\n",
    "\n",
    "\n",
    "def fix_latitude(input_latitude):\n",
    "    try:\n",
    "        input_latitude = float(input_latitude)\n",
    "    except:\n",
    "        return np.NaN\n",
    "    if input_latitude < southlimit or input_latitude > northlimit:\n",
    "        return np.NaN\n",
    "    return input_latitude\n",
    "\n",
    "\n",
    "def fix_df(df):\n",
    "    df['pickup_longitude']=df['pickup_longitude'].apply(fix_longitude)\n",
    "    df['dropoff_longitude']=df['dropoff_longitude'].apply(fix_longitude)\n",
    "    df['pickup_latitude']=df['pickup_latitude'].apply(fix_latitude)\n",
    "    df['dropoff_latitude']=df['dropoff_latitude'].apply(fix_latitude)\n",
    "    df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd606cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(csv_link):\n",
    "   \n",
    "    # make sure the output title is consistent \n",
    "    title = \"\"\n",
    "    m = re.search(r'(yellow.+)', csv_link)\n",
    "    if m:\n",
    "        title = m.group(1)\n",
    "   \n",
    "    #read the data into a dataframe\n",
    "    df = pd.read_csv(csv_link,on_bad_lines='skip')\n",
    "    df = df.rename(columns = lambda x: x.strip())\n",
    "   \n",
    "    #drop and rename column\n",
    "    to_drop = [\n",
    "        \"Unnamed: 0\",\n",
    "        \"vendor_name\",\n",
    "        \"vendor_id\",\n",
    "        \"Vendor_id\",\n",
    "        'VendorID',\n",
    "        \"Trip_distance\",\n",
    "        \"Trip_Distance\",\n",
    "        \"trip_distance\",\n",
    "        \"Rate_Code\",\n",
    "        \"store_and_forward\",\n",
    "        \"store_and_fwd_flag\",\n",
    "        \"Payment_Type\",\n",
    "        \"Fare_Amt\",\n",
    "        \"surcharge\",\n",
    "        \"mta_tax\",\n",
    "        \"Tolls_Amt\",\n",
    "        \"rate_code\",\n",
    "        \"RatecodeID\",\n",
    "        \"RateCodeID\",\n",
    "        \"payment_type\",\n",
    "        \"fare_amount\",\n",
    "        \"extra\",\n",
    "        \"tolls_amount\",\n",
    "        \"improvement_surcharge\",\n",
    "        \"Passenger_Count\",\n",
    "        \"passenger_count\"\n",
    "    ]\n",
    "    \n",
    "    mapper = {\n",
    "        \"Trip_Pickup_DateTime\" : \"pickup_time\",\n",
    "        \"tpep_pickup_datetime\" : \"pickup_time\",\n",
    "        \"pickup_datetime\": \"pickup_time\",\n",
    "        \"dropoff_datetime\" : \"dropoff_time\",\n",
    "        \"Trip_Dropoff_DateTime\" : \"dropoff_time\",\n",
    "        \"tpep_dropoff_datetime\" : \"dropoff_time\",\n",
    "        \"Start_Lon\" : \"pickup_longitude\",\n",
    "        \"Start_Lat\" : \"pickup_latitude\",\n",
    "        \"End_Lon\" : \"dropoff_longitude\",\n",
    "        \"End_Lat\" : \"dropoff_latitude\",\n",
    "        \"Tip_Amt\" : 'tip',\n",
    "        \"tip_amount\" : \"tip\",\n",
    "        \"Total_Amt\" : \"charge\",\n",
    "        \"total_amount\" : \"charge\"\n",
    "    }\n",
    "    df = df.drop(to_drop, axis = 1,errors = \"ignore\")\n",
    "    df = df.rename(mapper, axis = 1)\n",
    "    df.dropna(inplace = True)\n",
    "    \n",
    "    #modify datatype\n",
    "    df = df.astype({\"pickup_time\":np.datetime64,\"dropoff_time\": np.datetime64})\n",
    "    \n",
    "    \n",
    "    #make sure the trip is within(40.560445, -74.242330) and (40.908524, -73.717047)\n",
    "    fix_df(df)\n",
    "    \n",
    "    #sample 3000 rows\n",
    "    df = df.sample(n=3000)\n",
    "    \n",
    "    #add distance\n",
    "    add_distance(df)\n",
    "    df.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    df.to_csv(title,index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5684a7d8",
   "metadata": {},
   "source": [
    "run this to download all the yellow taxi sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd07a621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "links = get_csv_links()\n",
    "for i in tqdm(range(len(links))):\n",
    "    create_csv(links[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f936ede",
   "metadata": {},
   "source": [
    "## Storing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe0a7cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
